AWSTemplateFormatVersion: "2010-09-09"
Description: "Hail S3, AMI, and Service Catalog Stacks (qs-1qp776mgg)"

Metadata:
  QuickStartDocumentation:
    EntrypointName: "Launch into an existing VPC"
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "AWS Quick Start Configuration"
        Parameters:
         - "QSS3BucketName"
         - "QSS3KeyPrefix"
         - "QSS3BucketRegion"
      - Label:
          default: "Network Settings"
        Parameters:
          - "pVpcId"
          - "pSubnetId"
          - "pSubnetType"
      - Label:
          default: "Hail Settings"
        Parameters:
          - "pHailBucket"
          - "pCreateHailBucket"
          - "pSageMakerBucket"
          - "pCreateSageMakerBucket"
          - "pKmsEbsArn"
      - Label:
          default: "Tagging"
        Parameters:
          - "pTagEnvironment"
          - "pTagOwner"
    ParameterLabels:
      QSS3BucketName:
        default: Quick Start S3 bucket name
      QSS3KeyPrefix:
        default: Quick Start S3 key prefix
      QSS3BucketRegion:
        default: Quick Start S3 bucket region
      pKmsEbsArn:
        default: "EBS KMS Key ARN"
      pHailBucket:
        default: "Hail Bucket Name"
      pCreateHailBucket:
        default: "Create Hail Bucket"
      pSageMakerBucket:
        default: "Sagemaker Home Directory Bucket Name"
      pCreateSageMakerBucket:
        default: "Create SageMaker Bucket"
      pTagOwner:
        default: "Owner Tag"
      pTagEnvironment:
        default: "Environment Tag"
      pVpcId:
        default: "Existing VPC ID"
      pSubnetId:
        default: "Existing Subnet ID"
      pSubnetType:
        default: "Existing Subnet Type"

Parameters:

  QSS3BucketName:
    AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
    ConstraintDescription: "Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-)."
    Default: "aws-quickstart"
    Description: "S3 bucket name for the Quick Start assets. Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-)."
    Type: "String"

  QSS3KeyPrefix:
    AllowedPattern: "^[0-9a-zA-Z-/]*$"
    ConstraintDescription: "Quick Start key prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slash (/)."
    Default: "quickstart-hail/"
    Description: "S3 key prefix for the Quick Start assets. Quick Start key prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slash (/)."
    Type: "String"

  QSS3BucketRegion:
    Default: 'us-east-1'
    Description: The AWS Region where the Quick Start S3 bucket (QSS3BucketName) is hosted. When using your own bucket, you must specify this value.
    Type: String
  
  pHailBucket:
    AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
    Description: "EMR logs, cluster manifests, and VEP configuration files are placed here."
    Type: "String"

  pCreateHailBucket:
    Type: "String"
    Description: "Select No to use an existing bucket."
    AllowedValues:
      - "yes"
      - "no"
    Default: "yes"

  pKmsEbsArn:
    Description: "Optional - if the source AMI is encrypted specify the full key ARN.  Otherwise, leave blank.  This does NOT automatically enable EBS encryption."
    Default: ""
    Type: "String"

  pSageMakerBucket:
    AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
    Description: "Bucket for common Jupyter notebooks and SageMaker home directory backups."
    Type: "String"

  pCreateSageMakerBucket:
    Type: "String"
    Description: "Select No to use an existing bucket."
    AllowedValues:
      - "yes"
      - "no"
    Default: "yes"

  pTagEnvironment:
    AllowedValues:
      - "production"
      - "staging"
      - "development"
    Default: "development"
    Description: "Environment type for default resource tagging."
    Type: "String"

  pTagOwner:
    Type: "String"
    Description: "Optional - Owner of the resources.  Person/Department, etc."
    Default: ""

  pSubnetId:
    Description: "Required for existing VPC target. Subnet for EMR Cluster and SageMaker Notebook Instances.  Must reside in the existing VPC."
    Type: "AWS::EC2::Subnet::Id"

  pSubnetType:
    Description: "Required for existing VPC target. Public subnets deploy resources with public IPs.  Private subnets do not.  Private subnets are recommended."
    Type: "String"
    AllowedValues:
      - "public"
      - "private"
    Default: "private"

  pVpcId:
    Description: "Required - SageMaker security group is created in this VPC."
    Type: "AWS::EC2::VPC::Id"

Conditions:

    UsingDefaultBucket: !Equals
    - !Ref QSS3BucketName
    - 'aws-quickstart'

Resources:

  stackS3:
    Type: "AWS::CloudFormation::Stack"
    Properties:
      TemplateURL:
        !Sub
          - 'https://${S3Bucket}.s3.${S3Region}.${AWS::URLSuffix}/${QSS3KeyPrefix}templates/hail-s3.template.yaml'
          - S3Region: !If [UsingDefaultBucket, !Ref 'AWS::Region', !Ref QSS3BucketRegion]
            S3Bucket: !If [UsingDefaultBucket, !Sub '${QSS3BucketName}-${AWS::Region}', !Ref QSS3BucketName]
      Parameters:
        pHailBucket: !Ref pHailBucket
        pCreateHailBucket: !Ref pCreateHailBucket
        pSageMakerBucket: !Ref pSageMakerBucket
        pCreateSageMakerBucket: !Ref pCreateSageMakerBucket
        pTagEnvironment: !Ref pTagEnvironment
        pTagOwner: !Ref pTagOwner
      TimeoutInMinutes: 5

  stackAmi:
    DependsOn:
      - stackS3
    Type: "AWS::CloudFormation::Stack"
    Properties:
      TemplateURL:
        !Sub
          - 'https://${S3Bucket}.s3.${S3Region}.${AWS::URLSuffix}/${QSS3KeyPrefix}templates/hail-ami.template.yaml'
          - S3Region: !If [UsingDefaultBucket, !Ref 'AWS::Region', !Ref QSS3BucketRegion]
            S3Bucket: !If [UsingDefaultBucket, !Sub '${QSS3BucketName}-${AWS::Region}', !Ref QSS3BucketName]
      Parameters:
        pKmsEbsArn: !Ref pKmsEbsArn
        pHailBucket: !Ref pHailBucket
        pRodaHailBucket: !GetAtt rodaBucketParameter.Value
        pSubnetId: !Ref pSubnetId
        pSubnetType: !Ref pSubnetType
        pVpcId: !Ref pVpcId
      TimeoutInMinutes: 5

  stackServiceCatalog:
    Type: "AWS::CloudFormation::Stack"
    Properties:
      TemplateURL:
        !Sub
          - 'https://${S3Bucket}.s3.${S3Region}.${AWS::URLSuffix}/${QSS3KeyPrefix}templates/hail-service-catalog.template.yaml'
          - S3Region: !If [UsingDefaultBucket, !Ref 'AWS::Region', !Ref QSS3BucketRegion]
            S3Bucket: !If [UsingDefaultBucket, !Sub '${QSS3BucketName}-${AWS::Region}', !Ref QSS3BucketName]
      Parameters:
        QSS3BucketName: !Ref QSS3BucketName
        QSS3KeyPrefix: !Ref QSS3KeyPrefix
        QSS3BucketRegion: !Ref QSS3BucketRegion
      TimeoutInMinutes: 5

  sgSagemaker:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      VpcId: !Ref pVpcId
      GroupDescription: "Security group for SageMaker Notebook instances to connect to Hail clusters."
      SecurityGroupEgress:
        - IpProtocol: "-1"
          FromPort: -1
          ToPort: -1
          CidrIp: "0.0.0.0/0"
          Description: "all"
      Tags:
        - Key: "environment"
          Value: !Ref pTagEnvironment
        - Key: "owner"
          Value: !Ref pTagOwner

  sagemakerSgParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: "Security Group ID to attach to Hail SageMaker notebook instances."
      Name: "/hail/sagemaker/security-group-id"
      Type: "String"
      Value: !Ref sgSagemaker

  subnetIdParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: "Target subnet for Hail EMR cluster and SageMaker notebook instances."
      Name: "/hail/vpc/subnet-id"
      Type: "String"
      Value: !Ref pSubnetId

  vpcIdParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: "Target VPC for Hail EMR cluster and SageMaker notebook instances."
      Name: "/hail/vpc/id"
      Type: "String"
      Value: !Ref pVpcId

  subnetTypeParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: "Subnet type, public or private, for Hail resources.  Drives SageMaker notebook networking configuration."
      Name: "/hail/vpc/subnet-type"
      Type: "String"
      Value: !Ref pSubnetType

  roleLambdaS3seed:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        - PolicyName: "cloudwatch-log-write"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              Action:
                - "logs:CreateLogGroup"
                - "logs:CreateLogStream"
                - "logs:PutLogEvents"
              Resource: "arn:aws:logs:*:*:*"
              Effect: "Allow"
        - PolicyName: "hail-sagemaker-s3-put-object"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              Action:
                - "s3:PutObject"
              Resource:
                - !Sub "arn:aws:s3:::${pSageMakerBucket}/common-notebooks/*"
                - !Sub "arn:aws:s3:::${pSageMakerBucket}/scripts/*"
                - !Sub "arn:aws:s3:::${pHailBucket}/*"
              Effect: "Allow"
        - PolicyName: "s3-quickstart-list"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              Action:
                - "s3:ListBucket"
              Resource:
                - !Sub "arn:aws:s3:::${QSS3BucketName}"
              Effect: "Allow"
        - PolicyName: "s3-quickstart-get-object"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              Action:
                - "s3:GetObject"
              Resource:
                - !Sub "arn:aws:s3:::${QSS3BucketName}/*"
              Effect: "Allow"

  lambdaS3seed:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: "hail-code-copy-lambda"
      Handler: "index.lambda_handler"
      Role: !GetAtt roleLambdaS3seed.Arn
      Code:
        ZipFile: |
          import boto3
          import os
          from zipfile import ZipFile, ZIP_DEFLATED
          import urllib3
          import json


          s3_client = boto3.client("s3")
          s3_resource = boto3.resource("s3")
          http = urllib3.PoolManager()

          def cfnresponse_send(event, context, responseStatus, responseData, physicalResourceId=None, noEcho=False, reason=None):
              responseUrl = event['ResponseURL']
              print(responseUrl)

              responseBody = {
                  'Status' : responseStatus,
                  'Reason' : reason or "See the details in CloudWatch Log Stream: {}".format(context.log_stream_name),
                  'PhysicalResourceId' : physicalResourceId or context.log_stream_name,
                  'StackId' : event['StackId'],
                  'RequestId' : event['RequestId'],
                  'LogicalResourceId' : event['LogicalResourceId'],
                  'NoEcho' : noEcho,
                  'Data' : responseData
              }

              json_responseBody = json.dumps(responseBody)

              print("Response body:")
              print(json_responseBody)

              headers = {
                  'content-type' : '',
                  'content-length' : str(len(json_responseBody))
              }

              try:
                  response = http.request('PUT', responseUrl, headers=headers, body=json_responseBody)
                  print("Status code:", response.status)


              except Exception as e:

                  print("send(..) failed executing http.request(..):", e)
        


          def clone_githb_repo_locally(hail_quickstart_git_url, clone_directory):
              try:
                  os_command = "git clone %s %s" % (hail_quickstart_git_url, clone_directory)
                  os.system(os_command)
                  print("The github repo cloning completed successfully.")
              except:
                  raise Exception("The cloning from github repo failed. Kindly verify.")


          def create_zip_file(input_path):
              zip_file_name = os.path.join(input_path, "packer.zip")
              with ZipFile(zip_file_name, 'w', ZIP_DEFLATED) as zipObj:
                  # Iterate over all the files in directory
                  for folderName, subfolders, filenames in os.walk(input_path):
                      for filename in filenames:
                          # create complete filepath of file in directory
                          filePath = os.path.join(folderName, filename)
                          # Add file to zip
                          zipObj.write(filePath, os.path.basename(filePath))

              zipObj.close()
              print("The zip file created : " + str(zip_file_name))
              return zip_file_name


          def upload_file_to_s3(local_file, target_bucket, target_key=''):
              target_file_key = os.path.join(target_key, os.path.basename(local_file))
              s3_client.upload_file(local_file, target_bucket, target_file_key)
              print("The file : %s is uploaded at : s3://%s/%s" % (local_file, target_bucket, target_key))


          def upload_folder_to_s3(local_path, target_bucket, target_key=''):
              for root, dirs, files in os.walk(local_path):
                  for file in files:
                      target_file_key = os.path.join(target_key, file)
                      s3_client.upload_file(os.path.join(
                          root, file), target_bucket, target_file_key)
                      print("The File Uploaded at : s3://%s/%s" % (target_bucket, target_file_key))


          def delete_folders(bucket_name, folder_key):
              s3_resource.Bucket(bucket_name).objects.filter(
                  Prefix=folder_key + "/").delete()
              print("Folder deleted : s3://%s/%s" % (bucket_name, folder_key))


          def lambda_handler(event, context):
              try:
                  source_bucket = event["ResourceProperties"]["QSS3BucketName"]
                  quickstart_prefix = event["ResourceProperties"]["QSS3KeyPrefix"]
                  hail_bucket = event["ResourceProperties"]["HailBucketName"]
                  sagemaker_bucket = event["ResourceProperties"]["SageMakerBucketName"]
                  hail_quickstart_git_url = "https://github.com/aws-quickstart/quickstart-hail.git"
                  clone_directory = "/tmp/github_repo/hail-emr/"
                  
                  if event["RequestType"] in ["Create", "Update"]:
                      # Clone the github repo
                      clone_githb_repo_locally(hail_quickstart_git_url, clone_directory)

                      # Zip the packer file.
                      create_zip_file("%spacker" % clone_directory)

                      # Upload files from local to corresponding S3 Buckets
                      # Upload packer.zip to QSS3BucketName/ami/packer.zip
                      upload_file_to_s3(local_file="%spacker/packer.zip" % clone_directory, target_bucket=hail_bucket, target_key="ami")

                      # Upload scripts and common notebooks to sagemaker bucket
                      upload_folder_to_s3(local_path="%ssagemaker/common-notebooks" % clone_directory,
                                          target_bucket=sagemaker_bucket, target_key="common-notebooks")
                      upload_folder_to_s3(local_path="%ssagemaker/scripts" % clone_directory,
                                          target_bucket=sagemaker_bucket, target_key="scripts")

                      rdata = {"Status": "SUCCESS"}
                      cfnresponse_send(event, context, "SUCCESS", rdata)
                  elif event["RequestType"] == "Delete":
                      print("Delete Request by CFN...")
                      folder_details = [
                          {'bucket_name': hail_bucket, 'folder_key': 'ami'},
                          {'bucket_name': sagemaker_bucket, 'folder_key': "common-notebooks"},
                          {'bucket_name': sagemaker_bucket, 'folder_key': "scripts"}
                      ]
                      for record in folder_details:
                          delete_folders(record['bucket_name'], record['folder_key'])

                      rdata = {"Status": "Success"}
                      cfnresponse_send(event, context, "SUCCESS", rdata)

              except Exception as e:
                  print("[ERROR] - %s" % str(e))
                  rdata = {"Error": "Could not perform the operation"}
                  cfnresponse_send(event, context, "FAILED", rdata)

      Runtime: "python3.7"
      Layers:
        - !Sub "arn:aws:lambda:${AWS::Region}:553035198032:layer:git:14"
      Timeout: 300

  lambdaS3seedPermission:
    Type: "AWS::Lambda::Permission"
    Properties:
      Action: "lambda:InvokeFunction"
      Principal: "cloudformation.amazonaws.com"
      FunctionName: !GetAtt lambdaS3seed.Arn

  lambdaS3seedInvoke:
    DependsOn: lambdaS3seed
    Type: "Custom::InvokeLambdaFunction"
    Properties:
      QSS3BucketName: !Ref QSS3BucketName
      QSS3KeyPrefix: !Ref QSS3KeyPrefix
      HailBucketName: !Ref pHailBucket
      SageMakerBucketName: !Ref pSageMakerBucket
      ServiceToken: !GetAtt lambdaS3seed.Arn

  rodaBucketParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: "Registry of Open Data Hail S3 Bucket.  Contains VEP and LOFTEE data."
      Name: "/hail/s3/roda"
      Type: "String"
      Value: "hail-vep-pipeline"

Outputs:

  portfolio:
    Description: "Service Catalog Portfolio"
    Value: !GetAtt stackServiceCatalog.Outputs.portfolio

  bucketHail:
    Description: "Hail S3 Bucket"
    Value: !GetAtt stackS3.Outputs.bucketHail

  bucketSageMaker:
    Description: "SageMaker S3 Bucket"
    Value: !GetAtt stackS3.Outputs.bucketSageMaker